#!/usr/bin/env python3
"""
Advanced Mapping Pipeline with Parallel Processing and LLM Fallback

This module implements a sophisticated schema mapping pipeline that includes:
1. Parallel processing of rule-based and embedding engines
2. Confidence score aggregation from multiple sources
3. KNN-based filtering for complex cases
4. Intelligent LLM fallback logic
5. Rich context generation for LLM processing

Author: Schema Mapping System
Date: 2024
"""

import asyncio
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
from enum import Enum
import numpy as np
from sklearn.neighbors import NearestNeighbors
import json
from pathlib import Path

logger = logging.getLogger(__name__)

class FallbackPriority(Enum):
    MANDATORY = "mandatory"
    CONDITIONAL = "conditional"
    OPTIONAL = "optional"
    NONE = "none"

@dataclass
class ConfidenceBreakdown:
    rule_based_confidence: float
    embedding_confidence: float
    aggregated_confidence: float
    agreement_level: float
    uncertainty_factors: List[str]

@dataclass
class FieldContext:
    source_type: str
    target_type: str
    semantic_similarity: float
    type_compatibility: float
    pattern_similarity: float
    field_category: str
    is_phi_related: bool
    is_business_critical: bool
    semantic_ambiguity: float
    field_complexity: float

@dataclass
class KNNInsights:
    nearest_neighbors: List[Dict[str, Any]]
    cluster_patterns: Dict[str, Any]
    similarity_distribution: Dict[str, float]

@dataclass
class LLMFallbackDecision:
    use_llm: bool
    fallback_score: float
    reasons: List[str]
    priority: FallbackPriority
    rule_type: str

class AdvancedMappingPipeline:
    """
    Advanced mapping pipeline with parallel processing and intelligent fallback logic.
    """
    
    def __init__(self, rule_based_engine, embedding_engine, knn_analyzer, llm_processor):
        self.rule_based_engine = rule_based_engine
        self.embedding_engine = embedding_engine
        self.knn_analyzer = knn_analyzer
        self.llm_processor = llm_processor
        self.llm_queue = []
        
        # Configuration
        self.confidence_weights = {
            "rule_based": 0.4,
            "embedding": 0.6
        }
        
        self.fallback_thresholds = {
            "mandatory": 0.7,
            "conditional": 0.5,
            "optional": 0.3
        }
    
    async def execute_advanced_pipeline(self, source_schema: Dict[str, str], 
                                      target_schema: Dict[str, str]) -> Dict[str, Any]:
        """
        Execute the complete advanced mapping pipeline.
        """
        logger.info("ðŸš€ Starting Advanced Mapping Pipeline")
        
        # Stage 1: Parallel Processing
        logger.info("ðŸ“Š Stage 1: Parallel Processing")
        rule_results, embedding_results = await self._parallel_processing(source_schema, target_schema)
        
        # Stage 2: Confidence Aggregation
        logger.info("ðŸ”— Stage 2: Confidence Aggregation")
        aggregated_results = self._aggregate_confidence_scores(rule_results, embedding_results)
        
        # Stage 3: KNN Analysis for Complex Cases
        logger.info("ðŸ” Stage 3: KNN Analysis")
        knn_candidates = self._filter_for_knn_analysis(aggregated_results, source_schema, target_schema)
        
        # Stage 4: Rich Context Generation
        logger.info("ðŸ“ Stage 4: Rich Context Generation")
        enriched_candidates = self._generate_rich_context(knn_candidates, source_schema, target_schema)
        
        # Stage 5: LLM Fallback Logic
        logger.info("ðŸ¤– Stage 5: LLM Fallback Logic")
        llm_candidates = self._apply_fallback_logic(enriched_candidates)
        
        # Stage 6: LLM Processing
        logger.info("ðŸ§  Stage 6: LLM Processing")
        final_results = await self._process_llm_candidates(llm_candidates)
        
        # Generate comprehensive report
        report = self._generate_comprehensive_report(
            aggregated_results, enriched_candidates, final_results
        )
        
        return report
    
    async def _parallel_processing(self, source_schema: Dict[str, str], 
                                 target_schema: Dict[str, str]) -> Tuple[Dict, Dict]:
        """
        Execute rule-based and embedding engines in parallel.
        """
        loop = asyncio.get_event_loop()
        
        with ThreadPoolExecutor(max_workers=2) as executor:
            # Submit both tasks
            rule_future = loop.run_in_executor(
                executor, self.rule_based_engine.process, source_schema, target_schema
            )
            embedding_future = loop.run_in_executor(
                executor, self.embedding_engine.process, source_schema, target_schema
            )
            
            # Wait for both to complete
            rule_results, embedding_results = await asyncio.gather(rule_future, embedding_future)
        
        logger.info(f"âœ… Parallel processing completed - Rule: {len(rule_results)} results, Embedding: {len(embedding_results)} results")
        
        return rule_results, embedding_results
    
    def _aggregate_confidence_scores(self, rule_results: Dict, embedding_results: Dict) -> List[Dict[str, Any]]:
        """
        Aggregate confidence scores from multiple engines.
        """
        aggregated_results = []
        
        # Get all unique source fields
        all_source_fields = set(rule_results.keys()) | set(embedding_results.keys())
        
        for source_field in all_source_fields:
            rule_score = rule_results.get(source_field, {}).get("confidence", 0.0)
            embedding_score = embedding_results.get(source_field, {}).get("confidence", 0.0)
            
            # Calculate agreement level
            agreement_level = 1.0 - abs(rule_score - embedding_score)
            
            # Aggregate confidence with context-aware weighting
            aggregated_score = self._context_aware_aggregation(
                rule_score, embedding_score, source_field
            )
            
            # Apply agreement-based adjustments
            final_score = self._apply_agreement_adjustments(
                aggregated_score, agreement_level
            )
            
            # Identify uncertainty factors
            uncertainty_factors = self._identify_uncertainty_factors(
                rule_score, embedding_score, agreement_level
            )
            
            confidence_breakdown = ConfidenceBreakdown(
                rule_based_confidence=rule_score,
                embedding_confidence=embedding_score,
                aggregated_confidence=final_score,
                agreement_level=agreement_level,
                uncertainty_factors=uncertainty_factors
            )
            
            aggregated_results.append({
                "source_field": source_field,
                "confidence_breakdown": confidence_breakdown,
                "rule_based_result": rule_results.get(source_field, {}),
                "embedding_result": embedding_results.get(source_field, {}),
                "field_complexity": self._calculate_field_complexity(source_field),
                "semantic_ambiguity": self._calculate_semantic_ambiguity(source_field)
            })
        
        logger.info(f"âœ… Confidence aggregation completed - {len(aggregated_results)} fields processed")
        
        return aggregated_results
    
    def _context_aware_aggregation(self, rule_score: float, embedding_score: float, 
                                 field_name: str) -> float:
        """
        Perform context-aware confidence aggregation.
        """
        # Determine field characteristics
        is_standard_field = self._is_standard_field(field_name)
        is_domain_specific = self._is_domain_specific(field_name)
        
        # Adjust weights based on field characteristics
        if is_standard_field:
            weights = {"rule_based": 0.6, "embedding": 0.4}
        elif is_domain_specific:
            weights = {"rule_based": 0.3, "embedding": 0.7}
        else:
            weights = self.confidence_weights
        
        # Calculate weighted average
        aggregated_score = (
            rule_score * weights["rule_based"] + 
            embedding_score * weights["embedding"]
        )
        
        return aggregated_score
    
    def _apply_agreement_adjustments(self, base_score: float, agreement_level: float) -> float:
        """
        Apply agreement-based adjustments to confidence scores.
        """
        adjusted_score = base_score
        
        # Boost if engines agree
        if agreement_level > 0.8:
            agreement_boost = 0.1
            adjusted_score = min(1.0, adjusted_score + agreement_boost)
        elif agreement_level > 0.6:
            agreement_boost = 0.05
            adjusted_score = min(1.0, adjusted_score + agreement_boost)
        
        # Penalty if engines disagree significantly
        elif agreement_level < 0.4:
            disagreement_penalty = 0.15
            adjusted_score = max(0.0, adjusted_score - disagreement_penalty)
        elif agreement_level < 0.6:
            disagreement_penalty = 0.08
            adjusted_score = max(0.0, adjusted_score - disagreement_penalty)
        
        return adjusted_score
    
    def _identify_uncertainty_factors(self, rule_score: float, embedding_score: float, 
                                    agreement_level: float) -> List[str]:
        """
        Identify factors contributing to uncertainty.
        """
        uncertainty_factors = []
        
        if agreement_level < 0.6:
            uncertainty_factors.append("engine_disagreement")
        
        if rule_score < 0.5:
            uncertainty_factors.append("low_rule_confidence")
        
        if embedding_score < 0.5:
            uncertainty_factors.append("low_embedding_confidence")
        
        if abs(rule_score - embedding_score) > 0.3:
            uncertainty_factors.append("high_score_variance")
        
        return uncertainty_factors
    
    def _filter_for_knn_analysis(self, aggregated_results: List[Dict], 
                               source_schema: Dict[str, str], 
                               target_schema: Dict[str, str]) -> List[Dict]:
        """
        Filter results for KNN analysis and LLM processing.
        """
        knn_candidates = []
        
        for result in aggregated_results:
            confidence = result["confidence_breakdown"].aggregated_confidence
            complexity = result["field_complexity"]
            ambiguity = result["semantic_ambiguity"]
            
            # Criteria for KNN analysis
            if (confidence < 0.8 and  # Not high confidence
                complexity > 0.5 and  # Complex field
                ambiguity > 0.3):     # Ambiguous meaning
                
                knn_candidates.append(result)
        
        # Sort by priority (lower confidence = higher priority)
        knn_candidates.sort(key=lambda x: x["confidence_breakdown"].aggregated_confidence)
        
        # Limit to top candidates
        max_candidates = min(10, len(knn_candidates))
        knn_candidates = knn_candidates[:max_candidates]
        
        logger.info(f"âœ… KNN filtering completed - {len(knn_candidates)} candidates selected")
        
        return knn_candidates
    
    def _generate_rich_context(self, knn_candidates: List[Dict], 
                             source_schema: Dict[str, str], 
                             target_schema: Dict[str, str]) -> List[Dict]:
        """
        Generate rich context for each KNN candidate.
        """
        enriched_candidates = []
        
        for candidate in knn_candidates:
            source_field = candidate["source_field"]
            
            # Generate field context
            field_context = self._create_field_context(
                source_field, source_schema, target_schema
            )
            
            # Perform KNN analysis
            knn_insights = self._perform_knn_analysis(source_field, target_schema)
            
            # Enrich candidate with context
            enriched_candidate = {
                **candidate,
                "field_context": field_context,
                "knn_insights": knn_insights,
                "rich_context": self._build_rich_context(candidate, field_context, knn_insights)
            }
            
            enriched_candidates.append(enriched_candidate)
        
        logger.info(f"âœ… Rich context generation completed - {len(enriched_candidates)} candidates enriched")
        
        return enriched_candidates
    
    def _create_field_context(self, source_field: str, source_schema: Dict[str, str], 
                            target_schema: Dict[str, str]) -> FieldContext:
        """
        Create comprehensive field context.
        """
        source_type = source_schema.get(source_field, "")
        target_type = target_schema.get(source_field, "")  # Assuming same field name for now
        
        return FieldContext(
            source_type=source_type,
            target_type=target_type,
            semantic_similarity=self._calculate_semantic_similarity(source_field),
            type_compatibility=self._calculate_type_compatibility(source_type, target_type),
            pattern_similarity=self._calculate_pattern_similarity(source_field),
            field_category=self._categorize_field(source_field),
            is_phi_related=self._is_phi_field(source_field),
            is_business_critical=self._is_business_critical(source_field),
            semantic_ambiguity=self._calculate_semantic_ambiguity(source_field),
            field_complexity=self._calculate_field_complexity(source_field)
        )
    
    def _perform_knn_analysis(self, source_field: str, target_schema: Dict[str, str]) -> KNNInsights:
        """
        Perform KNN analysis for a field.
        """
        # Mock KNN analysis (in real implementation, use actual KNN)
        nearest_neighbors = [
            {"field": "field1", "similarity": 0.75, "distance": 0.25},
            {"field": "field2", "similarity": 0.65, "distance": 0.35},
            {"field": "field3", "similarity": 0.55, "distance": 0.45}
        ]
        
        cluster_patterns = {
            "cluster_id": 1,
            "cluster_size": 5,
            "cluster_center": [0.5, 0.3, 0.2]
        }
        
        similarity_distribution = {
            "mean": 0.65,
            "std": 0.15,
            "min": 0.45,
            "max": 0.85
        }
        
        return KNNInsights(
            nearest_neighbors=nearest_neighbors,
            cluster_patterns=cluster_patterns,
            similarity_distribution=similarity_distribution
        )
    
    def _build_rich_context(self, candidate: Dict, field_context: FieldContext, 
                          knn_insights: KNNInsights) -> Dict[str, Any]:
        """
        Build rich context for LLM processing.
        """
        return {
            "field_mapping": {
                "source_field": candidate["source_field"],
                "target_field": candidate.get("rule_based_result", {}).get("target_field", ""),
                "aggregated_confidence": candidate["confidence_breakdown"].aggregated_confidence
            },
            "field_characteristics": {
                "source_type": field_context.source_type,
                "target_type": field_context.target_type,
                "semantic_similarity": field_context.semantic_similarity,
                "type_compatibility": field_context.type_compatibility,
                "pattern_similarity": field_context.pattern_similarity,
                "semantic_ambiguity": field_context.semantic_ambiguity,
                "field_complexity": field_context.field_complexity
            },
            "domain_context": {
                "healthcare_domain": True,
                "field_category": field_context.field_category,
                "phi_related": field_context.is_phi_related,
                "business_critical": field_context.is_business_critical
            },
            "knn_insights": {
                "nearest_neighbors": knn_insights.nearest_neighbors,
                "cluster_patterns": knn_insights.cluster_patterns,
                "similarity_distribution": knn_insights.similarity_distribution
            },
            "confidence_breakdown": {
                "rule_based_confidence": candidate["confidence_breakdown"].rule_based_confidence,
                "embedding_confidence": candidate["confidence_breakdown"].embedding_confidence,
                "agreement_level": candidate["confidence_breakdown"].agreement_level,
                "uncertainty_factors": candidate["confidence_breakdown"].uncertainty_factors
            }
        }
    
    def _apply_fallback_logic(self, enriched_candidates: List[Dict]) -> List[Dict]:
        """
        Apply LLM fallback logic to enriched candidates.
        """
        llm_candidates = []
        
        for candidate in enriched_candidates:
            fallback_decision = self._determine_llm_fallback(candidate)
            candidate["llm_fallback"] = fallback_decision
            
            if fallback_decision.use_llm:
                llm_candidates.append(candidate)
        
        # Sort by priority
        llm_candidates.sort(key=lambda x: (
            x["llm_fallback"].priority.value if x["llm_fallback"].priority != FallbackPriority.NONE else 4,
            -x["llm_fallback"].fallback_score
        ))
        
        logger.info(f"âœ… Fallback logic applied - {len(llm_candidates)} candidates selected for LLM")
        
        return llm_candidates
    
    def _determine_llm_fallback(self, candidate: Dict) -> LLMFallbackDecision:
        """
        Determine when to use LLM based on multiple criteria.
        """
        fallback_score = 0.0
        fallback_reasons = []
        
        confidence = candidate["confidence_breakdown"].aggregated_confidence
        agreement_level = candidate["confidence_breakdown"].agreement_level
        field_context = candidate["field_context"]
        knn_insights = candidate["knn_insights"]
        
        # 1. Low aggregated confidence
        if confidence < 0.6:
            fallback_score += 0.3
            fallback_reasons.append("low_confidence")
        
        # 2. High disagreement between engines
        if agreement_level < 0.7:
            fallback_score += 0.25
            fallback_reasons.append("engine_disagreement")
        
        # 3. Complex field characteristics
        if field_context.semantic_ambiguity > 0.5:
            fallback_score += 0.2
            fallback_reasons.append("semantic_ambiguity")
        
        # 4. Business critical fields
        if field_context.is_business_critical:
            fallback_score += 0.15
            fallback_reasons.append("business_critical")
        
        # 5. PHI-related fields
        if field_context.is_phi_related:
            fallback_score += 0.1
            fallback_reasons.append("phi_related")
        
        # 6. KNN uncertainty
        if knn_insights.similarity_distribution["std"] > 0.2:
            fallback_score += 0.15
            fallback_reasons.append("knn_uncertainty")
        
        # Determine priority
        if fallback_score >= self.fallback_thresholds["mandatory"]:
            priority = FallbackPriority.MANDATORY
        elif fallback_score >= self.fallback_thresholds["conditional"]:
            priority = FallbackPriority.CONDITIONAL
        elif fallback_score >= self.fallback_thresholds["optional"]:
            priority = FallbackPriority.OPTIONAL
        else:
            priority = FallbackPriority.NONE
        
        return LLMFallbackDecision(
            use_llm=fallback_score >= self.fallback_thresholds["conditional"],
            fallback_score=fallback_score,
            reasons=fallback_reasons,
            priority=priority,
            rule_type="score_based"
        )
    
    async def _process_llm_candidates(self, llm_candidates: List[Dict]) -> List[Dict]:
        """
        Process LLM candidates based on priority.
        """
        processed_candidates = []
        
        for candidate in llm_candidates:
            if candidate["llm_fallback"].priority == FallbackPriority.MANDATORY:
                # Immediate LLM processing
                logger.info(f"ðŸ§  Processing mandatory LLM candidate: {candidate['source_field']}")
                llm_result = await self._process_with_llm(candidate["rich_context"])
                candidate["llm_result"] = llm_result
                processed_candidates.append(candidate)
            else:
                # Queue for batch processing
                self.llm_queue.append(candidate)
        
        # Process queued candidates in batch
        if self.llm_queue:
            logger.info(f"ðŸ§  Processing {len(self.llm_queue)} queued LLM candidates")
            batch_results = await self._process_llm_batch(self.llm_queue)
            processed_candidates.extend(batch_results)
        
        return processed_candidates
    
    async def _process_with_llm(self, rich_context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process a single candidate with LLM.
        """
        # Mock LLM processing (in real implementation, call actual LLM API)
        await asyncio.sleep(0.1)  # Simulate API call
        
        return {
            "mapping_suggestion": "suggested_target_field",
            "confidence": 0.85,
            "explanation": "LLM analysis suggests this mapping based on semantic similarity and domain context",
            "alternative_suggestions": ["alt_field1", "alt_field2"],
            "reasoning": "The field appears to represent similar concepts based on naming patterns and context"
        }
    
    async def _process_llm_batch(self, llm_queue: List[Dict]) -> List[Dict]:
        """
        Process LLM candidates in batch for efficiency.
        """
        # Mock batch processing
        await asyncio.sleep(0.5)  # Simulate batch API call
        
        processed_candidates = []
        for candidate in llm_queue:
            candidate["llm_result"] = {
                "mapping_suggestion": "batch_suggested_field",
                "confidence": 0.75,
                "explanation": "Batch LLM analysis completed",
                "alternative_suggestions": [],
                "reasoning": "Batch processing result"
            }
            processed_candidates.append(candidate)
        
        return processed_candidates
    
    def _generate_comprehensive_report(self, aggregated_results: List[Dict], 
                                     enriched_candidates: List[Dict], 
                                     final_results: List[Dict]) -> Dict[str, Any]:
        """
        Generate comprehensive final report.
        """
        total_fields = len(aggregated_results)
        high_confidence = len([r for r in aggregated_results if r["confidence_breakdown"].aggregated_confidence >= 0.8])
        medium_confidence = len([r for r in aggregated_results if 0.6 <= r["confidence_breakdown"].aggregated_confidence < 0.8])
        low_confidence = len([r for r in aggregated_results if r["confidence_breakdown"].aggregated_confidence < 0.6])
        
        llm_processed = len([r for r in final_results if "llm_result" in r])
        
        avg_confidence = sum(r["confidence_breakdown"].aggregated_confidence for r in aggregated_results) / total_fields
        
        return {
            "pipeline_summary": {
                "total_fields_processed": total_fields,
                "high_confidence_mappings": high_confidence,
                "medium_confidence_mappings": medium_confidence,
                "low_confidence_mappings": low_confidence,
                "llm_processed": llm_processed,
                "average_confidence": round(avg_confidence, 3)
            },
            "processing_breakdown": {
                "parallel_processing": "completed",
                "confidence_aggregation": "completed",
                "knn_analysis": len(enriched_candidates),
                "llm_processing": llm_processed
            },
            "final_mappings": [
                {
                    "source_field": r["source_field"],
                    "target_field": r.get("llm_result", {}).get("mapping_suggestion", 
                                 r.get("rule_based_result", {}).get("target_field", "")),
                    "confidence": r["confidence_breakdown"].aggregated_confidence,
                    "method": "llm" if "llm_result" in r else "aggregated",
                    "llm_explanation": r.get("llm_result", {}).get("explanation", "")
                }
                for r in final_results
            ],
            "performance_metrics": {
                "efficiency_score": round(high_confidence / total_fields * 100, 1),
                "quality_score": round(avg_confidence * 100, 1),
                "llm_usage_rate": round(llm_processed / total_fields * 100, 1)
            }
        }
    
    # Helper methods for field analysis
    def _is_standard_field(self, field_name: str) -> bool:
        """Check if field is a standard field type."""
        standard_fields = ['email', 'phone', 'name', 'id', 'date', 'address', 'city', 'state', 'zip']
        return any(standard in field_name.lower() for standard in standard_fields)
    
    def _is_domain_specific(self, field_name: str) -> bool:
        """Check if field is domain-specific."""
        domain_fields = ['npi', 'specialty', 'license', 'malpractice', 'accreditation', 'phi']
        return any(domain in field_name.lower() for domain in domain_fields)
    
    def _is_phi_field(self, field_name: str) -> bool:
        """Check if field contains PHI."""
        phi_indicators = ['ssn', 'birth', 'death', 'medical_record', 'patient_id', 'diagnosis']
        return any(phi in field_name.lower() for phi in phi_indicators)
    
    def _is_business_critical(self, field_name: str) -> bool:
        """Check if field is business critical."""
        critical_fields = ['npi', 'license', 'accreditation', 'compliance', 'quality']
        return any(critical in field_name.lower() for critical in critical_fields)
    
    def _categorize_field(self, field_name: str) -> str:
        """Categorize field based on naming patterns."""
        field_lower = field_name.lower()
        
        if any(word in field_lower for word in ['npi', 'id', 'number']):
            return "identifier"
        elif any(word in field_lower for word in ['name', 'title']):
            return "name"
        elif any(word in field_lower for word in ['date', 'time']):
            return "temporal"
        elif any(word in field_lower for word in ['phone', 'email', 'contact']):
            return "contact"
        elif any(word in field_lower for word in ['address', 'city', 'state', 'zip']):
            return "location"
        elif any(word in field_lower for word in ['specialty', 'certification', 'education']):
            return "professional"
        elif any(word in field_lower for word in ['rating', 'score', 'quality']):
            return "assessment"
        else:
            return "other"
    
    def _calculate_field_complexity(self, field_name: str) -> float:
        """Calculate field complexity score."""
        # Simple complexity calculation based on field characteristics
        complexity = 0.0
        
        if '_' in field_name:
            complexity += 0.2
        
        if len(field_name) > 15:
            complexity += 0.2
        
        if any(word in field_name.lower() for word in ['specialty', 'certification', 'accreditation']):
            complexity += 0.3
        
        if any(word in field_name.lower() for word in ['malpractice', 'disciplinary', 'compliance']):
            complexity += 0.3
        
        return min(1.0, complexity)
    
    def _calculate_semantic_ambiguity(self, field_name: str) -> float:
        """Calculate semantic ambiguity score."""
        # Simple ambiguity calculation
        ambiguity = 0.0
        
        if any(word in field_name.lower() for word in ['other', 'misc', 'additional']):
            ambiguity += 0.4
        
        if any(word in field_name.lower() for word in ['custom', 'user_defined', 'extended']):
            ambiguity += 0.3
        
        if len(field_name.split('_')) > 3:
            ambiguity += 0.2
        
        return min(1.0, ambiguity)
    
    def _calculate_semantic_similarity(self, field_name: str) -> float:
        """Calculate semantic similarity score."""
        # Mock semantic similarity calculation
        return 0.7  # Placeholder
    
    def _calculate_type_compatibility(self, source_type: str, target_type: str) -> float:
        """Calculate type compatibility score."""
        if source_type == target_type:
            return 1.0
        elif 'varchar' in source_type.lower() and 'varchar' in target_type.lower():
            return 0.8
        elif 'int' in source_type.lower() and 'int' in target_type.lower():
            return 0.8
        else:
            return 0.3
    
    def _calculate_pattern_similarity(self, field_name: str) -> float:
        """Calculate pattern similarity score."""
        # Mock pattern similarity calculation
        return 0.6  # Placeholder 